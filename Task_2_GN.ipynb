{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Importing Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from networkx.algorithms.community.centrality import girvan_newman\n",
    "from operator import mul\n",
    "import networkx as nx\n",
    "import os\n",
    "import sys\n",
    "import community.community_louvain as community\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.colors as mpcolors\n",
    "import matplotlib.cm as mpcm\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Loading DataSet**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_url = \"./Dataset/Cit-HepPh.txt\"\n",
    "df_data_1 = pd.read_csv(data_url, sep='\\t', skiprows=4, names=['FromNodeId', 'ToNodeId'], dtype={'FromNodeId': int, 'ToNodeId': int})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Loading Time of Release**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_url = \"./Dataset/cit-HepPh-dates.txt\"\n",
    "df_data_2 = pd.read_csv(data_url, sep='\\t', skiprows=1, names=['NodeId', 'Date'], dtype={'NodeId': str, 'Date': str})\n",
    "df_data_2['Date'] = pd.to_datetime(df_data_2['Date'])\n",
    "df_data_2 = df_data_2[~df_data_2['NodeId'].str.startswith('11')]\n",
    "df_data_2['NodeId'] = df_data_2['NodeId'].astype(str).str.lstrip('0')\n",
    "df_data_2['NodeId'] = df_data_2['NodeId'].astype(int)\n",
    "df_data_2 = df_data_2[df_data_2['Date'].dt.year <= 1992]\n",
    "# i = 0\n",
    "# unnodes = df_data_2['NodeId']\n",
    "# for nodes in unnodes:\n",
    "#     i += 1\n",
    "# print(i)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Merging Both DataSet**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = pd.merge(df_data_1, df_data_2, how='inner', left_on='FromNodeId', right_on='NodeId')\n",
    "df_merged['Date'] = pd.to_datetime(df_merged['Date'])\n",
    "# Filter out rows where 'ToNodeId' is not present in 'NodeId' column of df_data_2\n",
    "df_merged = df_merged[df_merged['ToNodeId'].isin(df_data_2['NodeId'])]\n",
    "unnodes = df_merged['FromNodeId'].unique()\n",
    "# i = 0\n",
    "# for nodes in unnodes:\n",
    "#     i += 1\n",
    "# print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Creation of Graph**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 173\n",
      "Number of edges: 152\n",
      "0.005108213469552359\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Construct the directed graph\n",
    "G_lat = nx.from_pandas_edgelist(df_merged, 'FromNodeId', 'ToNodeId', create_using=nx.DiGraph())\n",
    "\n",
    "print(\"Number of nodes:\", len(G_lat.nodes()))\n",
    "print(\"Number of edges:\", len(G_lat.edges()))\n",
    "print(nx.density(G_lat))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Girvan-Newman Algorithm**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Method 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edge_to_remove(g):\n",
    "    d1 = nx.edge_betweenness_centrality(g) \n",
    "    list_of_tuples = list(d1.items()) \n",
    "      \n",
    "    sorted(list_of_tuples, key = lambda x:x[1], reverse = True) \n",
    "      \n",
    "    # Will return in the form (a,b) \n",
    "    return list_of_tuples[0][0] \n",
    "\n",
    "def girvan(graph):\n",
    "    graph_cp = graph.copy()\n",
    "\n",
    "    init_comp = nx.number_weakly_connected_components(graph_cp)\n",
    "    while graph_cp.number_of_edges() > 0:\n",
    "\n",
    "        u ,v = edge_to_remove(graph_cp)\n",
    "        graph_cp.remove_edge(u,v)\n",
    "\n",
    "        new_comp = nx.number_weakly_connected_components(graph_cp)\n",
    "\n",
    "        # if new_comp > init_comp:\n",
    "        #     break;\n",
    "        if not nx.is_weakly_connected(graph_cp):\n",
    "            break\n",
    "    return list(nx.weakly_connected_components(graph_cp))\n",
    "\n",
    "scratch_communities = girvan(G_lat)\n",
    "\n",
    "# print(\"Final communities:\", communities)\n",
    "# for community in scratch_communities:\n",
    "#     print(community)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Method 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class community_algo:\n",
    "    def __init__(self, graph):\n",
    "        self.graph = graph\n",
    "        \n",
    "    \"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "    \"\"\"                               Main Functions                                 \"\"\"\n",
    "    \"\"\"                                                                              \"\"\"    \n",
    "    \"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "    def calculate_directed_modularity(self, G, partition):\n",
    "        m = G.number_of_edges()\n",
    "        modularity = 0.0\n",
    "        for community in set(partition.values()):\n",
    "            nodes_in_community = [node for node, comm in partition.items() if comm == community]\n",
    "            subgraph = G.subgraph(nodes_in_community)\n",
    "            e_wc = sum([subgraph.out_degree(node, weight='weight') for node in nodes_in_community])\n",
    "            a_c_out = sum([G.out_degree(node, weight='weight') for node in nodes_in_community])\n",
    "            a_c_in = sum([G.in_degree(node, weight='weight') for node in nodes_in_community])\n",
    "            modularity += (e_wc / m) - ((a_c_out / (2 * m)) * (a_c_in / (2 * m)))\n",
    "        return modularity\n",
    "    \n",
    "    def find_best_partition(self):\n",
    "        G = self.graph.copy()\n",
    "        g_modularity = 0.0\n",
    "        removed_edges = []\n",
    "        partition = {}\n",
    "        while 1:\n",
    "            betweenness = self.calculate_betweenness(G)\n",
    "            max_betweenness_edges = self.get_max_betweenness_edges(betweenness)\n",
    "            if len(G.edges()) == len(max_betweenness_edges):\n",
    "                break\n",
    "\n",
    "            G.remove_edges_from(max_betweenness_edges)  \n",
    "            components = nx.weakly_connected_components(G)\n",
    "            idx = 0\n",
    "            tmp_partition = {}\n",
    "            for component in components:\n",
    "                for inner in list(component):\n",
    "                    tmp_partition.setdefault(inner, idx)\n",
    "                idx += 1\n",
    "            cur_mod = self.calculate_directed_modularity(G, tmp_partition)\n",
    "\n",
    "            if cur_mod < g_modularity:\n",
    "                G.add_edges_from(max_betweenness_edges)\n",
    "                break\n",
    "            else:\n",
    "                partition = tmp_partition\n",
    "            removed_edges.extend(max_betweenness_edges)\n",
    "            g_modularity = cur_mod\n",
    "        return partition, G, removed_edges\n",
    "\n",
    "    def get_max_betweenness_edges(self, betweenness):\n",
    "        max_betweenness_edges = []\n",
    "        max_betweenness = max(betweenness.items(), key=lambda x: x[1])\n",
    "        for (k, v) in betweenness.items():\n",
    "            if v == max_betweenness[1]:\n",
    "                max_betweenness_edges.append(k)\n",
    "        return max_betweenness_edges\n",
    "\n",
    "    def calculate_betweenness(self, G):\n",
    "        betweenness = nx.edge_betweenness_centrality(G, k=None, normalized=True, weight=None, seed=None)\n",
    "        return betweenness\n",
    "    \n",
    "    def partition_to_community(self, partition):\n",
    "        result = {}\n",
    "        for (k, v) in partition.items():\n",
    "            result.setdefault(v, [])\n",
    "            result[v].append(k)\n",
    "        return result.values()\n",
    "\n",
    "    def display(self, partition):\n",
    "        comms = self.partition_to_community(partition)\n",
    "        for comm in comms:\n",
    "            comm.sort() # actually duplicate process here\n",
    "            print(comm)\n",
    "    \n",
    "c = community_algo(G_lat)\n",
    "partition, part_graph, removed_edges = c.find_best_partition()\n",
    "\n",
    "inbuilt_communities = c.partition_to_community(partition)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Method 3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the inbuilt Girvan-Newman algorithm to detect communities\n",
    "inbuilt_communities_generator = girvan_newman(G_lat,most_valuable_edge=None)\n",
    "inbuilt_communities = [c for c in next(inbuilt_communities_generator)]\n",
    "\n",
    "# for community in inbuilt_communities:\n",
    "#     print(community)\n",
    "\n",
    "\n",
    "# Assign random colors to each detected community ensuring uniqueness\n",
    "# community_colors = {}\n",
    "# used_colors = set()  # Set to store used colors\n",
    "# for i, community in enumerate(scratch_communities):\n",
    "#     color = \"#{:06x}\".format(random.randint(0, 0xFFFFFF))  # Generate a random hex color\n",
    "#     community_colors[i] = color\n",
    "#     used_colors.add(color)\n",
    "#     for node in community:\n",
    "#         G_lat.nodes[node]['community'] = i\n",
    "#         G_lat.nodes[node]['color'] = color\n",
    "\n",
    "# # Export the graph to GraphML format\n",
    "# nx.write_graphml(G_lat, \"graph_with_inbuilt_communities_unique_colors.graphml\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
