{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Importing Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from networkx.algorithms.community.centrality import girvan_newman"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Loading DataSet**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_url = \"./Dataset/Cit-HepPh.txt\"\n",
    "df_data_1 = pd.read_csv(data_url, sep='\\t', skiprows=4, names=['FromNodeId', 'ToNodeId'], dtype={'FromNodeId': int, 'ToNodeId': int})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Loading Time of Release**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "755\n"
     ]
    }
   ],
   "source": [
    "data_url = \"./Dataset/cit-HepPh-dates.txt\"\n",
    "df_data_2 = pd.read_csv(data_url, sep='\\t', skiprows=1, names=['NodeId', 'Date'], dtype={'NodeId': str, 'Date': str})\n",
    "df_data_2['Date'] = pd.to_datetime(df_data_2['Date'])\n",
    "df_data_2 = df_data_2[~df_data_2['NodeId'].str.startswith('11')]\n",
    "df_data_2['NodeId'] = df_data_2['NodeId'].astype(str).str.lstrip('0')\n",
    "df_data_2['NodeId'] = df_data_2['NodeId'].astype(int)\n",
    "df_data_2 = df_data_2[df_data_2['Date'].dt.year <= 1992]\n",
    "i = 0\n",
    "unnodes = df_data_2['NodeId']\n",
    "for nodes in unnodes:\n",
    "    i += 1\n",
    "print(i)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Merging Both DataSet**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105\n"
     ]
    }
   ],
   "source": [
    "df_merged = pd.merge(df_data_1, df_data_2, how='inner', left_on='FromNodeId', right_on='NodeId')\n",
    "df_merged['Date'] = pd.to_datetime(df_merged['Date'])\n",
    "# Filter out rows where 'ToNodeId' is not present in 'NodeId' column of df_data_2\n",
    "df_merged = df_merged[df_merged['ToNodeId'].isin(df_data_2['NodeId'])]\n",
    "unnodes = df_merged['FromNodeId'].unique()\n",
    "i = 0\n",
    "for nodes in unnodes:\n",
    "    i += 1\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Creation of Graph**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 173\n",
      "Number of edges: 152\n",
      "0.005108213469552359\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Construct the directed graph\n",
    "G_lat = nx.from_pandas_edgelist(df_merged, 'FromNodeId', 'ToNodeId', create_using=nx.DiGraph())\n",
    "\n",
    "print(\"Number of nodes:\", len(G_lat.nodes()))\n",
    "print(\"Number of edges:\", len(G_lat.edges()))\n",
    "print(nx.density(G_lat))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Yearly Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.005108213469552359\n"
     ]
    }
   ],
   "source": [
    "df_merged['Year'] = df_merged['Date'].dt.year\n",
    "density_by_year = {}\n",
    "dia_by_year = {}\n",
    "grouped = df_merged.groupby('Year')\n",
    "\n",
    "for year, group in grouped:\n",
    "    filtered_data = df_merged[df_merged['Year'] <= year]\n",
    "    G = nx.from_pandas_edgelist(filtered_data, 'FromNodeId', 'ToNodeId', create_using=nx.DiGraph())\n",
    "\n",
    "    density = nx.density(G)\n",
    "    # dia = nx.diameter(G)\n",
    "    print(density)\n",
    "\n",
    "    density_by_year[year] = density\n",
    "    # dia_by_year[year] = dia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Girvan-Newman Algorithm**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edge_to_remove(g):\n",
    "    d1 = nx.edge_betweenness_centrality(g) \n",
    "    list_of_tuples = list(d1.items()) \n",
    "      \n",
    "    sorted(list_of_tuples, key = lambda x:x[1], reverse = True) \n",
    "      \n",
    "    # Will return in the form (a,b) \n",
    "    return list_of_tuples[0][0] \n",
    "\n",
    "def girvan(graph):\n",
    "    graph_cp = graph.copy()\n",
    "\n",
    "    init_comp = nx.number_weakly_connected_components(graph_cp)\n",
    "    while True:\n",
    "        u ,v = edge_to_remove(graph_cp)\n",
    "        graph_cp.remove_edge(u,v)\n",
    "\n",
    "        new_comp = nx.number_weakly_connected_components(graph_cp)\n",
    "\n",
    "        if new_comp > init_comp:\n",
    "            break;\n",
    "    return list(nx.weakly_connected_components(graph_cp))\n",
    "\n",
    "scratch_communities = girvan(G_lat)\n",
    "# print(\"Final communities:\", communities)\n",
    "# for community in scratch_communities:\n",
    "#     print(community)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Checking Results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{9210240, 9209250, 9209220, 9207237, 9211207, 9210280, 9212267, 9209232, 9210257, 9207219, 9203220, 9210235, 9211286, 9206203, 9211228, 9211325}\n",
      "{9211234, 9208205, 9205247}\n",
      "{9207264, 9206242, 9207213, 9212269, 9212271, 9212284}\n",
      "{9212305, 9203210, 9209292, 9211230}\n",
      "{9212288, 9203201, 9203203, 9204228, 9209227, 9209233, 9210278, 9208231, 9211303, 9212216, 9212224, 9211334, 9211211, 9212235, 9211218, 9206227, 9211219, 9212248, 9210227, 9204216}\n",
      "{9208233, 9209246, 9212279}\n",
      "{9207236, 9205221}\n",
      "{9206205, 9212278, 9209295}\n",
      "{9209203, 9212252}\n",
      "{9212285, 9205238}\n",
      "{9207209, 9209299, 9207207}\n",
      "{9209268, 9204237}\n",
      "{9212233, 9212227, 9211244, 9207214}\n",
      "{9203202, 9209285, 9208230, 9203206, 9207208, 9208262, 9207243, 9205229, 9205230, 9212245, 9209206, 9209208, 9212219, 9212318}\n",
      "{9211267, 9212230, 9212295, 9209241, 9212205, 9209262, 9204207, 9208244, 9206230, 9209239, 9203225}\n",
      "{9205228, 9204206, 9211216, 9204212, 9209272}\n",
      "{9210233, 9204204, 9210276, 9211292}\n",
      "{9212296, 9207266, 9205205}\n",
      "{9210260, 9204215}\n",
      "{9209248, 9206241, 9210275, 9211248, 9212220}\n",
      "{9212226, 9209204, 9208253, 9211247}\n",
      "{9212210, 9207204}\n",
      "{9203213, 9210221}\n",
      "{9209296, 9206212}\n",
      "{9211226, 9212277}\n",
      "{9212251, 9212212, 9204222}\n",
      "{9211258, 9211236, 9207269}\n",
      "{9210281, 9203222}\n",
      "{9206222, 9206255, 9206225, 9207249, 9206261, 9211223, 9211225, 9204220}\n",
      "{9212273, 9212234, 9205233}\n",
      "{9209244, 9207278}\n",
      "{9205224, 9204213}\n",
      "{9206266, 9212299, 9210223}\n",
      "{9206249, 9211331, 9211275, 9206254}\n",
      "{9210209, 9205210}\n",
      "{9203216, 9207201, 9205226, 9203215}\n",
      "{9206216, 9212286, 9211215}\n",
      "{9206252, 9203207}\n",
      "{9211253, 9208254}\n",
      "{9204232, 9207230}\n",
      "{9207228, 9212231}\n",
      "Communities do not match.\n"
     ]
    }
   ],
   "source": [
    "# Use the inbuilt Girvan-Newman algorithm to detect communities\n",
    "inbuilt_communities_generator = girvan_newman(G_lat)\n",
    "inbuilt_communities = [c for c in next(inbuilt_communities_generator)]\n",
    "\n",
    "inbuilt_communities_sets = [set(community) for community in inbuilt_communities]\n",
    "scratch_communities_sets = [set(community) for community in scratch_communities]\n",
    "\n",
    "for community in inbuilt_communities:\n",
    "    print(community)\n",
    "\n",
    "if sorted(inbuilt_communities_sets) == sorted(scratch_communities_sets):\n",
    "    print(\"Communities match!\")\n",
    "else:\n",
    "    print(\"Communities do not match.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
